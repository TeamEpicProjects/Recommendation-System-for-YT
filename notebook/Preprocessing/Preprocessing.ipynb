{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "warnings.filterwarnings('ignore')\n",
    "FILE_NAME = '\\\\StateWise-Data'\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgarg\\Documents\\GitHub\\Recommendation-System-for-YT\\notebook\\Preprocessing\n",
      "C:\\Users\\vgarg\\Documents\\GitHub\\Recommendation-System-for-YT\\notebook\n",
      "C:\\Users\\vgarg\\Documents\\GitHub\\Recommendation-System-for-YT\n",
      "C:\\Users\\vgarg\\Documents\\GitHub\\Recommendation-System-for-YT\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "absolutepath = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "print(absolutepath)\n",
    "\n",
    "fileDirectory = os.path.dirname(absolutepath)\n",
    "print(fileDirectory)#Path of parent directory\n",
    "parentDirectory = os.path.dirname(fileDirectory)\n",
    "print(parentDirectory)\n",
    "#Navigate to Strings directory\n",
    "newPath = os.path.join(parentDirectory, 'data', 'raw')   \n",
    "\n",
    "print(newPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzipping the datafile from data raw folder to \n",
    "with zipfile.ZipFile(newPath+FILE_NAME+'.zip',\"r\") as zip_ref:\n",
    "    zip_ref.extractall(absolutepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\vgarg\\\\Documents\\\\GitHub\\\\Recommendation-System-for-YT\\\\notebook\\\\Preprocessing\\\\StateWise-Data\\\\Chattishgarh\\\\youTubeSearchListChattishgarh.csv',\n",
       " 'C:\\\\Users\\\\vgarg\\\\Documents\\\\GitHub\\\\Recommendation-System-for-YT\\\\notebook\\\\Preprocessing\\\\StateWise-Data\\\\Haryana\\\\youTubeSearchListHaryana.csv',\n",
       " 'C:\\\\Users\\\\vgarg\\\\Documents\\\\GitHub\\\\Recommendation-System-for-YT\\\\notebook\\\\Preprocessing\\\\StateWise-Data\\\\MadhyaPradesh\\\\youTubeSearchListMadyaPradesh.csv',\n",
       " 'C:\\\\Users\\\\vgarg\\\\Documents\\\\GitHub\\\\Recommendation-System-for-YT\\\\notebook\\\\Preprocessing\\\\StateWise-Data\\\\Maharastra\\\\youTubeSearchListMaharastra.csv',\n",
       " 'C:\\\\Users\\\\vgarg\\\\Documents\\\\GitHub\\\\Recommendation-System-for-YT\\\\notebook\\\\Preprocessing\\\\StateWise-Data\\\\TamilNadu\\\\youTubeSearchListTamilNadu.csv',\n",
       " 'C:\\\\Users\\\\vgarg\\\\Documents\\\\GitHub\\\\Recommendation-System-for-YT\\\\notebook\\\\Preprocessing\\\\StateWise-Data\\\\Telangana\\\\youTubeSearchListTelangana.csv']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = []\n",
    "for root,dirs,files in os.walk(absolutepath):\n",
    "    for file in files:\n",
    "        if (file.find('.csv')>1):\n",
    "            data_files.append(root+'\\\\'+file)\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(data_files[4],index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ContentId</th>\n",
       "      <th>title</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>dislikeCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DPgTI-qO_uc</td>\n",
       "      <td>True beauty #shors#Truebeauty#kdrama#LeeSuHo#H...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-06T18:31:40Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PT40S</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07MEle9JSdo</td>\n",
       "      <td>penthouse #shorts#kdrama#koreandrama#edit#kdra...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-05T19:13:52Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PT14S</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIH02FlY-Qc</td>\n",
       "      <td>üíîüíî #shorts#kdrama#koreandrama#edit#kdramaedit#...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-05T19:09:04Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PT9S</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t9ISH4DtrM4</td>\n",
       "      <td>üî•üî•üî• #shorts#kdramaedit#kdrama#itsoknottobeokay...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-21T18:47:25Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PT11S</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pr4BEqNMYBA</td>\n",
       "      <td>This scene üòØüòçüî• #shorts#kdrama#doomatyourservic...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-20T17:51:11Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PT22S</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ContentId                                              title viewCount  \\\n",
       "0  DPgTI-qO_uc  True beauty #shors#Truebeauty#kdrama#LeeSuHo#H...         5   \n",
       "1  07MEle9JSdo  penthouse #shorts#kdrama#koreandrama#edit#kdra...         7   \n",
       "2  AIH02FlY-Qc  üíîüíî #shorts#kdrama#koreandrama#edit#kdramaedit#...         6   \n",
       "3  t9ISH4DtrM4  üî•üî•üî• #shorts#kdramaedit#kdrama#itsoknottobeokay...         6   \n",
       "4  Pr4BEqNMYBA  This scene üòØüòçüî• #shorts#kdrama#doomatyourservic...         1   \n",
       "\n",
       "  likeCount dislikeCount commentCount favoriteCount           publishedAt  \\\n",
       "0         1            0            0             0  2021-10-06T18:31:40Z   \n",
       "1         1            0            0             0  2021-10-05T19:13:52Z   \n",
       "2         1            0            0             0  2021-10-05T19:09:04Z   \n",
       "3         2            0            0             0  2021-09-21T18:47:25Z   \n",
       "4         1            0            0             0  2021-09-20T17:51:11Z   \n",
       "\n",
       "  description duration tags  \n",
       "0         NaN    PT40S   []  \n",
       "1         NaN    PT14S   []  \n",
       "2         NaN     PT9S   []  \n",
       "3         NaN    PT11S   []  \n",
       "4         NaN    PT22S   []  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136349, 11)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for null value count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContentId            0\n",
       "title                0\n",
       "viewCount        31482\n",
       "likeCount        31482\n",
       "dislikeCount     31482\n",
       "commentCount     31482\n",
       "favoriteCount    31482\n",
       "publishedAt      31482\n",
       "description      34621\n",
       "duration         31483\n",
       "tags             31483\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 136349 entries, 0 to 104866\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   ContentId      136349 non-null  object\n",
      " 1   title          136349 non-null  object\n",
      " 2   viewCount      104867 non-null  object\n",
      " 3   likeCount      104867 non-null  object\n",
      " 4   dislikeCount   104867 non-null  object\n",
      " 5   commentCount   104867 non-null  object\n",
      " 6   favoriteCount  104867 non-null  object\n",
      " 7   publishedAt    104867 non-null  object\n",
      " 8   description    101728 non-null  object\n",
      " 9   duration       104866 non-null  object\n",
      " 10  tags           104866 non-null  object\n",
      "dtypes: object(11)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Object dtype to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].convert_dtypes()\n",
    "df['description'] = df['description'].convert_dtypes()\n",
    "df['tags'] = df['tags'].convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 136349 entries, 0 to 104866\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   ContentId      136349 non-null  object\n",
      " 1   title          136349 non-null  string\n",
      " 2   viewCount      104867 non-null  object\n",
      " 3   likeCount      104867 non-null  object\n",
      " 4   dislikeCount   104867 non-null  object\n",
      " 5   commentCount   104867 non-null  object\n",
      " 6   favoriteCount  104867 non-null  object\n",
      " 7   publishedAt    104867 non-null  object\n",
      " 8   description    104866 non-null  string\n",
      " 9   duration       104866 non-null  object\n",
      " 10  tags           104866 non-null  string\n",
      "dtypes: object(8), string(3)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104866 entries, 0 to 104865\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   ContentId      104866 non-null  object\n",
      " 1   title          104866 non-null  string\n",
      " 2   viewCount      104866 non-null  object\n",
      " 3   likeCount      104866 non-null  object\n",
      " 4   dislikeCount   104866 non-null  object\n",
      " 5   commentCount   104866 non-null  object\n",
      " 6   favoriteCount  104866 non-null  object\n",
      " 7   publishedAt    104866 non-null  object\n",
      " 8   description    104866 non-null  string\n",
      " 9   duration       104866 non-null  object\n",
      " 10  tags           104866 non-null  string\n",
      "dtypes: object(8), string(3)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContentId        0\n",
       "title            0\n",
       "viewCount        0\n",
       "likeCount        0\n",
       "dislikeCount     0\n",
       "commentCount     0\n",
       "favoriteCount    0\n",
       "publishedAt      0\n",
       "description      0\n",
       "duration         0\n",
       "tags             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing tags, special characters and digits, convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"\",\"\",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['text'] = df['title'] + df['description'] + df['tags']\n",
    "df['text'] = df['text'].apply(lambda x:pre_process(x))\n",
    "\n",
    "#show the second 'text' just for fun\n",
    "df['text'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a vocabulary of words, \n",
    "Ignore words that appear in 85% of documents, \n",
    "Eliminate stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivshaurya/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:382: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['come', 'vis', 'viser', 'visest'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "def get_stop_words(stop_file_path):\n",
    "    \"\"\"load stop words \"\"\"\n",
    "    \n",
    "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "        return frozenset(stop_set)\n",
    "\n",
    "#load a set of stop words\n",
    "stopwords=get_stop_words(\"resources/stopwords.txt\")\n",
    "\n",
    "#get the text column \n",
    "docs=df['text'].tolist()\n",
    "\n",
    "#create a vocabulary of words, \n",
    "#ignore words that appear in 85% of documents, \n",
    "#eliminate stop words\n",
    "cv=CountVectorizer(max_df=0.85,stop_words=stopwords)\n",
    "word_count_vector=cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101727, 200019)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['learn',\n",
       " 'drama',\n",
       " 'kdrama',\n",
       " 'koreandrama',\n",
       " 'kcdrama',\n",
       " 'koreanwords',\n",
       " 'annyeong',\n",
       " 'kdramagirls',\n",
       " 'hello',\n",
       " 'lovers']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv.vocabulary_.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you only needs to do this once, this is a mapping of index to \n",
    "feature_names=cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate tf-idf for the given document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-idf 10000\n",
      "Collecting tf-idf 20000\n",
      "Collecting tf-idf 30000\n",
      "Collecting tf-idf 40000\n",
      "Collecting tf-idf 50000\n",
      "Collecting tf-idf 60000\n",
      "Collecting tf-idf 70000\n",
      "Collecting tf-idf 80000\n",
      "Collecting tf-idf 90000\n",
      "Collecting tf-idf 100000\n",
      "101727\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "tex_list = df['text'].tolist()\n",
    "tf_idf_vector_list = []\n",
    "for i in range(len(tex_list)):\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform([tex_list[i]]))\n",
    "    i = i+1\n",
    "    tf_idf_vector_list.append(tf_idf_vector)\n",
    "    # added to list  \n",
    "    if ((i%10000) == 0):\n",
    "        print ('Collecting tf-idf',i)\n",
    "print(len(tf_idf_vector_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort the tf-idf vectors by descending order of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting Done for 10000\n",
      "Sorting Done for 20000\n",
      "Sorting Done for 30000\n",
      "Sorting Done for 40000\n",
      "Sorting Done for 50000\n",
      "Sorting Done for 60000\n",
      "Sorting Done for 70000\n",
      "Sorting Done for 80000\n",
      "Sorting Done for 90000\n",
      "Sorting Done for 100000\n"
     ]
    }
   ],
   "source": [
    "sorted_items_list=[]\n",
    "i=0\n",
    "for i in range(len(tf_idf_vector_list)):\n",
    "    sorted_items=sort_coo(tf_idf_vector_list[i].tocoo())\n",
    "    i = i+1\n",
    "    sorted_items_list.append(sorted_items)\n",
    "    # added to list  \n",
    "    if ((i%10000) == 0):\n",
    "        print ('Sorting Done for',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101727"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_items_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract only the top n; n here is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topn_from_vector(feature_names, sorted_items, topn=5):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords added for 10000\n",
      "Keywords added for 20000\n",
      "Keywords added for 30000\n",
      "Keywords added for 40000\n",
      "Keywords added for 50000\n",
      "Keywords added for 60000\n",
      "Keywords added for 70000\n",
      "Keywords added for 80000\n",
      "Keywords added for 90000\n",
      "Keywords added for 100000\n"
     ]
    }
   ],
   "source": [
    "keyword_list = []\n",
    "i=0\n",
    "for i in range(len(sorted_items_list)):\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items_list[i],5)\n",
    "    i = i+1\n",
    "    keyword_list.append(keywords)\n",
    "    # added to list  \n",
    "    if ((i%10000) == 0):\n",
    "        print ('Keywords added for',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'kdrama': 0.46,\n",
       "  'koreanwords': 0.307,\n",
       "  'kdramagirls': 0.307,\n",
       "  'annyeong': 0.307,\n",
       "  'kcdrama': 0.297},\n",
       " {'mv': 0.53,\n",
       "  'lovealarms': 0.381,\n",
       "  'se√±orita': 0.314,\n",
       "  'alarm': 0.262,\n",
       "  'ytvideo': 0.191},\n",
       " {'kdrama': 0.421,\n",
       "  'savgegirls': 0.281,\n",
       "  'savagegirlsjkoreandrama': 0.281,\n",
       "  'howyoulikethatpart': 0.281,\n",
       "  'dlcfhts': 0.281},\n",
       " {'thetaleoftheninetailedep': 0.359,\n",
       "  'engsub': 0.347,\n",
       "  'tailed': 0.326,\n",
       "  'kdrama': 0.269,\n",
       "  'tale': 0.25},\n",
       " {'thetaleoftheninetailedepisode': 0.43,\n",
       "  'thetaleoftheninetailedfullepisode': 0.215,\n",
       "  'leeyoen': 0.215,\n",
       "  'koreandramawithengsub': 0.215,\n",
       "  'kdramaengsub': 0.215}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Title=====\n",
      "Things I learn from k drama\n",
      "\n",
      "=====Description=====\n",
      "#kdrama#koreandrama#kcdrama#koreanwords#annyeong#kdramagirls\n",
      "\n",
      "\n",
      "\n",
      "********************************************\n",
      "\n",
      "Hello kdrama lovers!! \n",
      "I made a ew edit for all of you i hope all of you ll like it if you like it please like share subscribe and do comment to my channel\n",
      "Tysm ‚ô• \n",
      "keep supporting ‚ô•\n",
      "\n",
      "===Top5 Keywords===\n",
      "kdrama 0.46\n",
      "koreanwords 0.307\n",
      "kdramagirls 0.307\n",
      "annyeong 0.307\n",
      "kcdrama 0.297\n",
      "\n",
      "=====Title=====\n",
      "Love alarm mv x Se√±orita shawn mendes korean mix song\n",
      "\n",
      "=====Description=====\n",
      "#kdrama#ytvideo#lovealarms1mv#mv#lovealarm#lovealarms1#kdramamv#se√±orita#kdramalovealarm#musicvideo#koreanmix\n",
      "\n",
      "********************************************\n",
      "\n",
      "Hello!! \n",
      "K-drama lover i made a short mv of love alarm i hope all of you like it if you like it please like share and do subscribe to my channel.\n",
      "Thank you ‚ô• \n",
      "Keep suppourting ‚ù§‚ù§\n",
      "\n",
      "===Top5 Keywords===\n",
      "mv 0.53\n",
      "lovealarms 0.381\n",
      "se√±orita 0.314\n",
      "alarm 0.262\n",
      "ytvideo 0.191\n",
      "\n",
      "=====Title=====\n",
      "K-drama savage girls part 2 (comment down your first k drama)\n",
      "\n",
      "=====Description=====\n",
      "#kdrama#savagegirlsjkoreandrama#howyoulikethatpart2#koreandrama#kcdrama\n",
      "\n",
      "********************************************\n",
      "\n",
      "hello! \n",
      "guys i made an edit of kdrama savgegirls i hope all of you like it if you it pleases like share comment and do subscribe to my channel and give your love to my channel \n",
      "Thank you \n",
      "Keep supporting üíúüíú\n",
      "\n",
      "********************************************\n",
      " \n",
      "Here is the link of 1 part üëáüëá\n",
      "\n",
      "https://youtu.be/DLcfHtS94OM\n",
      "\n",
      "===Top5 Keywords===\n",
      "kdrama 0.421\n",
      "savgegirls 0.281\n",
      "savagegirlsjkoreandrama 0.281\n",
      "howyoulikethatpart 0.281\n",
      "dlcfhts 0.281\n",
      "\n",
      "=====Title=====\n",
      "The tale of the nine tailed part 1 eng sub\n",
      "\n",
      "=====Description=====\n",
      "#thetaleoftheninetailed#thetaleoftheninetailedep1part1#thetaleoftheninetailedep1part1engsub#thetaleoftheninetailedpart1withengsub#engsub#kdrama#koreandrama#kdramawithengsub#Leeyeon#Leedongwook#Namjiah#Joboah#kimbum\n",
      "\n",
      "********************************************\n",
      "\n",
      "\n",
      "hello guys\n",
      "its my first video\n",
      "its was a kdrama the tale of the nine tailed episode 1 part 1 with eng sub i hope all of you like it if you like it please like share comment and do subscribe my channel and give your love to my channel thank you\n",
      "\n",
      "===Top5 Keywords===\n",
      "thetaleoftheninetailedep 0.359\n",
      "engsub 0.347\n",
      "tailed 0.326\n",
      "kdrama 0.269\n",
      "tale 0.25\n",
      "\n",
      "=====Title=====\n",
      "The tale of the nine tailed episode 1\n",
      "\n",
      "=====Description=====\n",
      "#thetaleoftheninetailed#kdrama#k&cdrama#thetaleoftheninetailedepisode1#koreandrama#koreandramawithengsub#kdramaengsub#thetaleoftheninetailedfullepisode#thetaleoftheninetailedepisode1withengsub#engsub#fullrpisode#fullepisodewithengsub#LeeDongWook#JoBoAh#LeeYoen#NamJiAh#kimBum\n",
      "\n",
      "********************************************\n",
      "\n",
      "Hello guys! \n",
      "Its my first video i hope you like it if you like please like share comment and do subscribe and give your love to my channel.\n",
      "Thank you.\n",
      "\n",
      "===Top5 Keywords===\n",
      "thetaleoftheninetailedepisode 0.43\n",
      "thetaleoftheninetailedfullepisode 0.215\n",
      "leeyoen 0.215\n",
      "koreandramawithengsub 0.215\n",
      "kdramaengsub 0.215\n"
     ]
    }
   ],
   "source": [
    "# now print the results\n",
    "for i  in range(5):\n",
    "    print(\"\\n=====Title=====\")\n",
    "    print(df['title'][i])\n",
    "    print(\"\\n=====Description=====\")\n",
    "    print(df['description'][i])\n",
    "    print(\"\\n===Top5 Keywords===\")\n",
    "    for k in keyword_list[i]:\n",
    "        print(k,keyword_list[i][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
